{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('data\\General_validation_text.jsonl', lines = True)\n",
    "df.drop(columns = ['id'], inplace = True)\n",
    "df.rename(columns = {'article' : 'input_text', 'highlights': \"target_text\"}, inplace = True)\n",
    "df.to_json('data\\General_validation_text.jsonl', orient = 'records',lines = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddcfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "#load long-T5\n",
    "model_name = \"google/long-t5-tglobal-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "data = pd.read_json('data/General_train_text_chunk_1.jsonl', lines = True)\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "#Tokenize\n",
    "def preprocess(example):\n",
    "    input_text = [\"summarize: \" + x for x in example[\"input_text\"]]\n",
    "    inputs = tokenizer(input_text, padding = \"max_length\", max_length = 4096, truncation = True)\n",
    "    targets = tokenizer(example[\"target_text\"], padding = \"max_length\", max_length = 256, truncation = True)\n",
    "\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched = True, remove_columns = dataset.column_names)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./longt5-summarizer\",            \n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",               \n",
    "    logging_dir=\"./logs\",                \n",
    "    fp16=torch.cuda.is_available(),      \n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "#Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_dataset,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab409fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc17396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('data\\General_train_text_chunk_1.jsonl', lines = True)\n",
    "your_article_text = df.at[0, 'input_text']\n",
    "ans = df.at[0, 'target_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1533165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp333\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/long-t5-tglobal-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc0bf2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp333\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py:1006: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daniel radcliffe as harry potter in \"harry potter and the order of the phoenix\" to the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties.\n",
      "Harry potter star daniel radcliffe gets Â£20m fortune as he turns 18 monday . Young actor says he has no plans to fritter his cash away . Radcliffe's earnings from first five potter films have been held in trust fund .\n"
     ]
    }
   ],
   "source": [
    "text = \"summarize: \" + your_article_text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=4096, truncation=True)\n",
    "\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], max_length=256, num_beams=4, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(summary)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a03b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp333\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\hp333\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp333\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Choose your model (e.g., \"t5-small\" or \"google/long-t5-tglobal-base\")\n",
    "model_name = \"t5-small\"  # or your actual model name\n",
    "\n",
    "# Load model and tokenizer from Hugging Face\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Save them locally\n",
    "tokenizer.save_pretrained(\"./my_local_t5/tokenizer\")\n",
    "model.save_pretrained(\"./my_local_t5/model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
